# **1. 개요 (Overview)**

본 문서는 'Everytime Canvas' 기능의 핵심 사용자 경험(UX)을 사전에 검증하기 위한 인터랙티브 웹 데모 페이지 기획안입니다. 실제 제품과 동일한 환경(커뮤니티 댓글, 채팅)에서 사용자가 AI 콘텐츠 생성 기능을 직접 체험하게 함으로써, 기능의 매력도와 사용성을 평가하고 개발 우선순위를 확정하는 것을 목표로 합니다.

# **2. 데모 페이지 목표 (Objectives)**

- **핵심 가치 검증:** 사용자들이 '키워드/스케치 기반 AI 콘텐츠 생성' 기능에 실제로 흥미를 느끼고 가치를 경험하는지 확인합니다.
- **사용자 경험(UX) 테스트:** 커뮤니티 댓글과 채팅이라는 각기 다른 맥락에서 기능이 얼마나 직관적이고 편리하게 동작하는지 테스트합니다.
- **피드백 수집:** 실제 사용자의 정성적/정량적 피드백을 수집하여 본 개발 시 개선점을 도출합니다.

**3. 핵심 기능 정의 (Scope of Demo)**

데모 페이지에서는 'Everytime Canvas'의 두 가지 핵심 생성 방식만을 구현합니다.

- **① 키워드 기반 생성:** 사용자가 입력한 키워드에 맞는 밈/이미지를 AI가 생성하여 여러 후보를 제시하는 기능
- **② 스케치 기반 생성:** 사용자가 미니 그림판에 간단히 그린 스케치를 AI가 완성도 있는 이미지로 변환해주는 기능

# **4. 페이지 구성 및 UI/UX 디자인**

웹 데모 페이지는 사용자가 실제 에브리타임 앱을 사용하는 것처럼 느낄 수 있도록 **[A. 커뮤니티 댓글]**과 **[B. 1:1 채팅]** 두 가지 시나리오로 구성됩니다.

---

### **[A] 커뮤니티 댓글 기능 시연**

**1) 화면 구성**

- 상단에는 "AI 캔버스 기능으로 더 재미있게 댓글을 달아보세요!"와 같은 안내 문구가 표시됩니다.
- 중앙에는 실제 에브리타임 게시글과 유사한 형태의 샘플 게시글(`제목: 시험 끝난 사람?`, `내용: 드디어 시험 끝! 너무 행복하다...`)이 배치됩니다.
- 하단에는 사용자가 직접 인터랙션할 수 있는 댓글 입력창이 위치합니다.

**2) 사용자 플로우 (User Flow) & UI**

1. 사용자는 익숙한 댓글 입력창에 텍스트를 입력합니다.
2. 입력창 우측 하단에 있는 **`🎨캔버스` 아이콘**을 발견하고 클릭합니다.
3. 화면 위로 **[AI 캔버스 생성 모달(Modal)]** 창이 나타납니다.
4. 모달 상단에는 **[① 키워드로 생성], [② 스케치로 생성]** 2개의 탭이 있어 원하는 방식을 선택할 수 있습니다.
    - **(키워드 선택 시):** 텍스트 입력창에 `'시험 해방'`을 입력하고 `[생성]` 버튼을 누릅니다. 잠시 후, AI가 생성한 4개의 관련 이미지(환호하며 뛰쳐나가는 학생, 불타는 책 등)가 갤러리 형태로 표시됩니다.
    - **(스케치 선택 시):** 간단한 그림판이 나타납니다. 사용자가 웃는 얼굴을 그리면, `[변환]` 버튼 클릭 시 AI가 이를 더 귀엽고 완성도 있는 이모티콘/이미지로 변환하여 보여줍니다.
5. 생성된 결과물 중 가장 마음에 드는 이미지를 클릭합니다.
7. 완성된 결과물 중 특정 결과물에 대해 수정을 요청할 수도 있습니다.
8. 모달 창이 닫히고, 선택한 이미지가 댓글 입력창에 썸네일 형태로 첨부됩니다. 텍스트와 함께 입력할 수 있습니다.
9. `[등록]` 버튼을 누르면, 사용자의 댓글(텍스트+AI 이미지)이 샘플 게시글 아래에 실시간으로 달리는 것을 시각적으로 확인할 수 있습니다.

---

### **[B] 1:1 채팅 기능 시연**

**1) 화면 구성**

- 카카오톡이나 DM과 유사한 1:1 채팅방 UI로 구성됩니다.
- 상대방(봇)이 먼저 말을 거는 형태(`상대방: 시험 잘 봤어?`)로 시나리오가 시작됩니다.
- 하단에는 메시지 입력창이 위치합니다.

**2) 사용자 플로우 (User Flow) & UI**

1. 사용자는 하단 메시지 입력창 좌측의 **`+` 버튼**을 클릭합니다.
2. [사진], [앨범] 등의 메뉴와 함께 **`🎨캔버스` 아이콘**이 나타나며, 이를 클릭합니다.
3. 커뮤니티 시나리오와 동일한 **[AI 캔버스 생성 모달]**이 열립니다.
4. 사용자는 키워드 또는 스케치 방식으로 원하는 감정(예: '완전 망했어')을 표현하는 이미지를 생성합니다.
5. 마음에 드는 이미지를 선택하고 `[전송]` 버튼을 누릅니다.
6. 텍스트 없이, 생성된 AI 이미지만으로 구성된 말풍선이 채팅창에 즉시 전송됩니다.
7. 잠시 후 상대방(봇)이 "ㅋㅋㅋㅋㅋ", "힘내ㅠㅠ" 와 같은 리액션을 보내주어 실제 대화 경험을 강화합니다.

# **5. 기술 구현 방안 (보강 및 구체화)**

본 데모는 단순 API 호출을 넘어, 확장 가능한 AI 에이전트 생태계의 기반을 다지는 것을 목표로 합니다. 이를 위해 **Orchestration Framework**를 도입하고, **지능형 캐싱(Intelligent Caching)** 메커니즘을 구현합니다.

### **5.1. 제안 아키텍처 (Proposed Architecture)**

전체 시스템은 다음과 같은 흐름으로 동작합니다.

```
[User] -> [Frontend (React)] -> [Backend (NestJS)] -> [AI Agent Executor (LangGraph)]
```

**AI Agent Executor 내부 흐름:**

```
(Start)
   |
   V
[1. 입력 분석 및 정규화 노드]
   |
   V
[2. 지능형 캐시 조회 노드 (RAG)] --> (유사 이미지 발견 시) --> [4. 최종 결과 반환]
   |
(유사 이미지 미발견 시)
   |
   V
[3. 이미지 생성 노드 (Bedrock)]
   |
   V
[4. 최종 결과 반환 및 캐시 저장]
   |
   V
(End)
```

### **5.2. 핵심 기술 요소 및 역할**

#### **가. Backend: NestJS**

  - **역할:** API Gateway 및 AI 에이전트 실행 환경 제공
  - **장점:**
      - TypeScript 기반으로 안정적이고 구조화된 개발이 가능합니다.
      - 모듈 기반 아키텍처는 향후 에이전트 기능을 추가하고 확장하기에 매우 용이합니다.
      - AWS SDK for JavaScript v3와 완벽하게 호환되어 Bedrock, S3, DynamoDB 등 AWS 서비스와 손쉽게 통합할 수 있습니다.

#### **나. AI Orchestration: LangChain & LangGraph**

  - **역할:** AI 로직의 흐름을 정의하고 제어하는 '두뇌' 역할
  - **LangChain:** AI 모델(Bedrock), 외부 도구(캐시 DB), 프롬프트 등을 연결하는 기본적인 '체인(Chain)'을 구성하는 데 사용됩니다.
  - **LangGraph:** 본 프로젝트의 핵심으로, 상태(State)를 가진 에이전트를 구현합니다. 단순한 순차 실행(Chain)을 넘어, 조건에 따라 분기하고(캐시 조회 성공/실패), 상태를 기억하며(Memory), 순환적인 워크플로우를 만들 수 있어 에이전트 아키텍처에 필수적입니다.
      - **예시:** `LangGraph`를 사용해 위 'AI Agent Executor 내부 흐름' 다이어그램과 같은 노드(Node)와 엣지(Edge)로 구성된 그래프를 정의하고 실행합니다.

#### **다. 지능형 캐싱 (Intelligent Caching) - RAG 패턴 활용**

Bedrock API 호출 비용을 절감하고 응답 속도를 향상시키기 위해, **기존에 생성된 이미지를 재활용**하는 지능형 캐싱 시스템을 구축합니다. 이는 단순한 Key-Value 캐시를 넘어, 의미적/시각적 유사도를 기반으로 검색하는 **RAG(Retrieval-Augmented Generation)** 패턴을 차용하여 구현합니다.

  - **작동 방식:**

    1.  **텍스트 기반 (Keyword):**
          - 사용자가 프롬프트('시험 해방')를 입력하면, 해당 텍스트의 \*\*벡터 임베딩(Vector Embedding)\*\*을 생성합니다. (e.g., `Amazon Titan Embeddings G1 - Text`)
          - 이 임베딩과 **유사한 벡터**를 Vector DB에서 검색합니다.
          - 유사도 점수가 특정 임계값(e.g., 95%) 이상인 이미지가 존재하면, Bedrock을 호출하는 대신 해당 이미지를 반환합니다.
    2.  **스케치 기반 (Sketch):**
          - 사용자가 그린 스케치 이미지를 **멀티모달 임베딩 모델**을 사용하여 벡터로 변환합니다.
          - 이후 과정은 텍스트 기반과 동일하게 Vector DB에서 유사한 이미지 벡터를 검색하여 재활용합니다.

  - **필요 기술:**

      - **Vector DB:** 생성된 이미지의 메타데이터(프롬프트, 이미지 S3 주소)와 벡터 임베딩을 저장하고 검색하는 데이터베이스. (e.g., `Amazon OpenSearch Serverless`, `Pinecone`, `ChromaDB`)
      - **Embedding Model:** 텍스트나 이미지를 벡터로 변환하는 모델. Bedrock 내장 모델을 활용할 수 있습니다.

#### **라. 이미지 생성: Amazon Bedrock**

  - **역할:** 실제 이미지를 생성하는 Foundation Model 제공
  - **사용 모델 예시:** `Amazon Titan Image Generator G1`, `Stability.ai Stable Diffusion XL` 등
  - **장점:**
      - 별도의 인프라 관리 없이 안정적인 이미지 생성 AI를 API 형태로 사용할 수 있습니다.
      - NestJS 백엔드에서 AWS SDK를 통해 안전하고 간단하게 호출할 수 있습니다.

#### **마. 상태 관리: LangGraph Memory**

  - **역할:** 대화의 맥락을 기억하여 일관성 있는 사용자 경험을 제공합니다.
  - **적용:** 특히 **[B] 1:1 채팅 기능**에서 중요합니다.
      - 사용자가 "이거 좀 더 웃기게 만들어줘" 라고 추가 요청 시, 이전 대화(어떤 이미지를 생성했는지)를 `Memory`에서 가져와 더 나은 결과물을 생성할 수 있습니다.
      - 이는 단순한 이미지 생성을 넘어, 사용자와 상호작용하는 '에이전트'의 느낌을 주는 핵심 요소입니다.

### **5.3. NestJS + Bedrock 구현 가능성 검토**

**결론: 완벽하게 가능하며, 매우 이상적인 조합입니다.**

1.  **AWS SDK 지원:** `NestJS`는 Node.js 환경이므로 `AWS SDK for JavaScript`를 사용하여 Bedrock을 비롯한 모든 AWS 서비스를 손쉽게 호출할 수 있습니다. `@aws-sdk/client-bedrock-runtime` 패키지를 사용하면 됩니다.
2.  **환경 변수 관리:** NestJS의 `ConfigModule`을 사용하면 AWS 자격 증명(Access Key, Secret Key)이나 Bedrock 모델 ID 등을 안전하고 체계적으로 관리할 수 있습니다.
3.  **비동기 처리:** 이미지 생성은 시간이 걸리는 작업입니다. NestJS는 `async/await`를 완벽하게 지원하므로, Bedrock API를 비동기적으로 호출하고 응답을 처리하는 데 매우 효율적입니다.
4.  **확장성:** 데모가 성공하여 실제 서비스로 확장될 경우, NestJS의 모듈식 아키텍처와 AWS의 서버리스 서비스(e.g., Lambda, Fargate)를 결합하여 MAU 500만 이상도 감당할 수 있는 안정적인 서비스로 발전시키기 용이합니다.

# **6. 데모 성공 측정 지표**

(기존 지표에 아래 항목 추가)

  - **캐시 히트율 (Cache Hit Rate):** 전체 이미지 생성 요청 중 Bedrock API를 호출하지 않고 캐시에서 처리된 요청의 비율. (아키텍처의 효율성 및 비용 절감 효과 측정)
  - **평균 응답 시간 (Average Response Time):** 사용자가 '생성' 버튼을 누른 후 이미지를 받기까지 걸리는 시간. (캐시 시스템의 성능 향상 효과 측정)
